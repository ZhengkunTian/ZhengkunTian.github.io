<!DOCTYPE HTML>
<!--
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Zhengkun Tian's Blog</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo">Stay Hungry. Stay Foolish.</a>
									<!--
									<ul class="icons">
										<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon brands fa-snapchat-ghost"><span class="label">Snapchat</span></a></li>
										<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="#" class="icon brands fa-medium-m"><span class="label">Medium</span></a></li>
									</ul>
								-->
								</header>

							<!-- Banner -->
								<section id="banner">
									<div class="content">
										<header>
											<h1>Hi, I’m <br> Zhengkun Tian. </h1>
											<p>A PhD Student in the Institute of Automation, Chinese Academy of Sciences (CASIA).</p>
										</header>
										<p>我对机器学习和语音技术很感兴趣. 目前主要的研究方向是语音识别，尤其侧重于端到端模型。我希望有朝一日，每个人都会有自己的语音助手，他们能以离线的方式部署在智能手机，个人电脑或者智能音箱等设备中。并且他们不需要占用很高的内存，也不会上传用户数据到云端服务器，因此也不用担心隐私泄露问题。加油！</p>

										<p>I have a strong interest in machine learning and speech technology. At present, the main research direction is speech recognition, especially end-to-end speech recognition. I hope that one day, everyone will have their voice assistant, they can be deployed in our mobile phones, personal computers or smart speakers and other devices in an offline way. They do not need a lot of memory space, nor upload user data to the cloud server, so there is no need to worry about privacy disclosure. Let's go for it.</p>
										<!--
										<ul class="actions">
											<li><a href="#" class="button big">Learn More</a></li>
										</ul>
										-->
									</div>

									<span class="image object">
										<img src="images/tianzhengkun.jpg" alt=""/>
									</span>

								</section>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Publications</h2>
									</header>
									<div class="content">
										<li>Zhengkun Tian, Jiangyan Yi, Jianhua Tao, Ye Bai, Zhengqi Wen. <a href="https://arxiv.org/pdf/1909.13037">Self-attention transducers for end-to-end speech recognition</a>. Interspeech 2019.</li>
										<li>Zhengkun Tian, Jiangyan Yi, Ye Bai, Jianhua Tao, Shuai Zhang, Zhengqi Wen. <a href="https://arxiv.org/pdf/1912.02958">Synchronous Transformers for End-to-End Speech Recognition</a>. ICASSP 2020.</li>
										<li>Zhengkun Tian, Jiangyan Yi, Jianhua Tao, Ye Bai, Shuai Zhang, Zhengqi Wen. <a href="https://arxiv.org/pdf/2005.07903">Spike-Triggered Non-Autoregressive Transformer for End-to-End Speech Recognition</a>. arXiv preprint.</li>
										<li>Ye Bai, Jiangyan Yi, Jianhua Tao, Zhengkun Tian, Zhengqi Wen. <a href="https://arxiv.org/pdf/1907.06017">Learn spelling from teachers: Transferring knowledge from language models to sequence-to-sequence speech recognition</a>. Interspeech 2019.</li>
										<li>Ye Bai, Jiangyan Yi, Jianhua Tao, Zhengqi Wen, Zhengkun Tian, Chenghao Zhao, Cunhang Fan. <a href="https://pdfs.semanticscholar.org/b106/9056e5a87ac342050403ae87692053456463.pdf">A Time Delay Neural Network with Shared Weight Self-Attention for Small-Footprint Keyword Spotting</a>. Interspeech 2019.</li>
										<li>Ye Bai, Jiangyan Yi, Jianhua Tao, Zhengkun Tian, Zhengqi Wen, Shuai Zhang. <a href="https://arxiv.org/pdf/2005.04862">Listen Attentively, and Spell Once: Whole Sentence Generation via a Non-Autoregressive Architecture for Low-Latency Speech Recognition</a>. arXiv preprint.</li>
										<li>Jiangyan Yi, Jianhua Tao, Ye Bai, Zhengkun Tian, Cunhang Fan. <a href="https://arxiv.org/pdf/2004.00248">Adversarial Transfer Learning for Punctuation Restoration</a>. arXiv preprint.</li>
										<li>Shuai Zhang, Jiangyan Yi, Zhengkun Tian, Jianhua Tao, Ye Bai. <a href="https://arxiv.org/pdf/2002.08126">RNN-transducer with language bias for end-to-end Mandarin-English code-switching speech recognition</a>. arXiv preprint.</li>
										<li>Bocheng Zhao, Jianhua Tao, Minghao Yang, Zhengkun Tian, Cunhang Fan, Ye Bai. <a href="http://159.226.21.68/bitstream/173211/28352/1/elsarticle-template-num-updateversion.pdf">Deep imitator: handwriting calligraphy imitation via deep attention networks</a>. Pattern Recognition.</li>
										<li>Ye Bai, Jiangyan Yi, Jianhua Tao, Zhengkun Tian, Zhengqi Wen, Shuai Zhang. <a href="https://arxiv.org/pdf/1912.01777">Integrating Whole Context to Sequence-to-sequence Speech Recognition</a>. arXiv preprint.</li>
									</div>
								</section>
						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section>

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="index.html">Homepage</a></li>
										<!--<li><a href="generic.html">Generic</a></li>-->
										<!--<li><a href="elements.html">Elements</a></li>-->
										<li>
											<span class="opener">ASR</span>
											<ul>
												<li><a href="blogs/tmp/md.html">Lorem Dolor</a></li>
												<li><a href="blogs/tmp/tmp.html">Ipsum Adipiscing</a></li>
												<li><a href="#">Tempus Magna</a></li>
												<li><a href="#">Feugiat Veroeros</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">NLP</span>
											<ul>
												<li><a href="#">Lorem Dolor</a></li>
												<li><a href="#">Ipsum Adipiscing</a></li>
												<li><a href="#">Tempus Magna</a></li>
												<li><a href="#">Feugiat Veroeros</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Other Topic</span>
											<ul>
												<li><a href="#">Lorem Dolor</a></li>
												<li><a href="#">Ipsum Adipiscing</a></li>
												<li><a href="#">Tempus Magna</a></li>
												<li><a href="#">Feugiat Veroeros</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Experiments</span>
											<ul>
												<li><a href="#">Lorem Dolor</a></li>
												<li><a href="#">Ipsum Adipiscing</a></li>
												<li><a href="#">Tempus Magna</a></li>
												<li><a href="#">Feugiat Veroeros</a></li>
											</ul>
								</nav>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<p>If you are interested in my research or want to cooperate, you can contact me.</p>
									<ul class="contact">
										<li class="icon solid fa-envelope"><a href="#">zhengkun.tian@nlpr.ia.ac.cn</a></li>
									</ul>
								</section>

							<!-- Footer -->
							<!--
								<footer id="footer">
									<p class="copyright">&copy; Untitled. All rights reserved. Demo Images: <a href="https://unsplash.com">Unsplash</a>. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
								</footer>
							-->
						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
